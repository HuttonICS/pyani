{
 "metadata": {
  "name": "",
  "signature": "sha256:a953ee90acf88e9d6ec6b1d288ebf248084ac1cc91757b82b94ee266bdaea0cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using `pyani` as a module"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook presents an introductory example of using the `pyani` module as a Python module, rather than using the helper script."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from pyani import pyani_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A typical use case for `pyani` would be to\n",
      "\n",
      "1. Identify a set of genome files\n",
      "2. Apply an ANI algorithm (ANIb, ANIm, ANIblastall, TETRA)\n",
      "3. Generate output\n",
      "\n",
      "The module's helper script wraps this process up with a range of command-line options and logging, so the module can be used as if it were a standalone program. Sometimes you may want to run ANI programmatically, and that is what this notebook will focus on."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Using `pyani` as a module"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2a. Specifying input files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`pyani` expects FASTA sequence files, where each individual file represents a single organism. It does not matter greatly that the FASTA sequence represents a complete, closed genome or a fragment in multiple parts. It doesn't matter whether the file contains a chromosome and a plasmid (or plasmids). Typically each file should, however, represent the completest genome available to you for a specific organism/isolate."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although the helper script expects all input FASTA files to be in the same directory, this is not true when using the module programmatically. Any list of valid paths to FASTA files can be used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accessions = ('NC_002696', 'NC_011916', 'NC_010338', 'NC_014100')\n",
      "datadir = os.path.join('..', 'tests', 'test_ani_data')\n",
      "filelist1 = [os.path.join(datadir, '%s.fna' % f) for f in accessions]\n",
      "print(filelist1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also use one of the module functions to collect all FASTA files from a single directory, if that is helpful:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filelist2 = pyani_files.get_fasta_files(datadir)\n",
      "print(filelist2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2b. Applying an Algorithm (long form)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `pyani` module provides for three ANI algorithms, and also the `TETRA` algorithm for whole-genome comparisons:\n",
      "\n",
      "* `ANIm`\n",
      "* `ANIb`\n",
      "* `ANIblastall`\n",
      "* `TETRA`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The three ANI algorithms can be used in a similar way:\n",
      "\n",
      "1. Generate a group of command-line jobs to be run, specifying input files and a location for output files (and any other useful parameters)\n",
      "2. Pass these command-lines to one of the scheduler wrappers (`multiprocessing` for local cores, or GridEngine)\n",
      "3. Process the output\n",
      "4. Use the output (e.g. write to file, or generate graphical output)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Example: `ANIm`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For example, running `ANIm` on the sequences defined in `filelist1` above, placing the output in `../tests/test_docs_anim`, using the default `NUCmer` executable, we first generate a list of `Job`s, which are the command-line arguments to be run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyani import anim\n",
      "\n",
      "# Make sure our planned output directory exists\n",
      "outdir = \"../tests/test_docs_anim\"\n",
      "if not os.path.isdir(outdir):\n",
      "    os.mkdir(outdir)\n",
      "\n",
      "jobs = anim.generate_jobs(filelist1, outdir=outdir)\n",
      "print(jobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each of the `Job`s corresponds to a single command-line that needs to be run to conduct `ANIm`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(jobs[0].command)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each `Job` can have a dependency on other jobs that need to be run first. For `ANIm` this isn't a concern, but for BLAST-based analyses, databases may need to be created before comparisons can be performed. The list of jobs returned above is actually a *dependency graph* that describes both the command-line jobs and the order in which they should run."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To run the jobs, we can employ an available job scheduler to run these commands in parallel. For Python2.6+, the `multiprocessing` module should be available and take advantage of all local cores. If you are running on a cluster with GridEngine, this scheduler can also be used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use local multiprocessing\n",
      "from pyani import run_multiprocessing as run_mp\n",
      "retval = run_mp.run_dependency_graph(jobs)\n",
      "print(\"multiprocessing returns {0}\".format(retval))\n",
      "\n",
      "# Use GridEngine scheduler\n",
      "#from pyani import run_sge\n",
      "#run_sge.run_dependency_graph(jobs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The return value `retval` is useful for bailing on failed multiprocessing runs, as this is only not zero if at least one submitted job does not run as intended."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the `NUCmer` calculations have been run for `ANIm`, we can process the output to calculate `ANIm`. We need to pass the original list of sequence files along with the output directory, as the `ANIm` calculation uses the sequence lengths."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = anim.process_deltadir(filelist1, outdir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The returned `result` is a tuple of four `Pandas` dataframes, representing in order:\n",
      "\n",
      "* alignment_lengths - total length of alignment\n",
      "* percentage_identity - percentage identity of alignment\n",
      "* alignment_coverage - coverage of query and subject\n",
      "* similarity_errors - count of similarity errors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for r in result:\n",
      "    print(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Being `Pandas` `DataFrames`, they can be presented in slightly prettier fashion:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(type(result[0]))\n",
      "result[0] # alignment lengths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also, the `DataFrame` methods for writing the table out to file are all available:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write dataframe to tab-separated format\n",
      "outfile = os.path.join(outdir, \"aln_lengths.tab\")\n",
      "result[0].to_csv(outfile, index=True, sep=\"\\t\")\n",
      "\n",
      "# What does the output look like?\n",
      "with open(outfile) as fh:\n",
      "    print fh.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `pyani_graphics` module has code for rendering heatmaps from these `DataFrames`."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}